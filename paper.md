---
title: Dynamic Routing Between Capsules (2017)
author: Sara Sabour, Geoffrey E. Hinton
model: CapsNets
description: None
---

---

ⓒ 2017 JMC

---

## 00 Abstract

캡슐은 뉴런 그룹으로, 개체 또는 개체 파트와 같은 특정 유형의 엔터티의 인스턴스화 매개 변수를 나타냅니다.
활동 벡터의 길이는 엔터티가 존재할 확률을 나타내고 활동 벡터의 방향은 인스턴스화 매개 변수를 나타냅니다.
활성 캡슐은 한 수준에서 변환 매트릭스를 통해 상위 수준 캡슐의 인스턴스화 매개 변수에 대한 예측을합니다.
여러 예측이 일치하면 더 높은 레벨의 캡슐이 활성화됩니다.
우리의 논문은 차별적으로 훈련된 멀티 레이어 캡슐넷이 MNIST에서 최첨단 성능을 달성하고 매우 겹쳐 있는 숫자를 인식할 때 CNN보다 훨씬 더 뛰어나다는 것을 보여줍니다.
이 결과를 얻으려면 반복적인 "라우팅 별 계약(routing by agreement)" 메커니즘을 사용하십시오.
하위 레벨 캡슐은 하위 레벨 캡슐에서 오는 예측과 함께 활동 벡터에 큰 스칼라 내적값이 있는 상위 캡슐로 출력을 보내기를 원합니다.

## 01 Introduction

사람의 시력은 주의 깊게 결정된 고정점 시퀀스를 사용하여 관련이 없는 세부 사항을 무시하므로 광 배열의 극히 일부만이 최고 해상도로 처리됩니다.
인트로스펙션은 한 장면에 대한 우리의 지식 중 많은 부분이 고정점 시퀀스에 기인한 것인지, 하나의 고정점에서 얼마나 많이 수집되었는지에 대해 이해가 부족한 지침입니다.
그러나 이 글에서는 단일 고정점이 단일 식별된 객체와 그 속성보다 훨씬 많은 것을 제공한다고 가정합니다.
우리는 다중 계층 시각 시스템이 각 고정점에 파스 트리(parse tree)와 같은 구조를 생성한다고 가정하고 이러한 단일 고정점 파스 트리가 여러 고정점을 통해 어떻게 조정되는지에 대한 문제는 무시합니다.

파스 트리는 일반적으로 메모리를 동적으로 할당하여 즉석에서 생성됩니다.
그러나 Hinton의 의견을 따라서 우리는 조각이 바위 위에 새겨져있는 것처럼 단 하나의 고정점마다 파스 트리가 고정된 다층 신경망에 새겨져 있다고 가정해야 합니다.
각 계층은 "캡슐"이라고 불리는 여러 개의 작은 뉴런 그룹으로 나뉘며, 파스 트리의 각 노드는 활성 캡슐에 해당합니다.
반복적인 라우팅 프로세스를 사용하여 각 활성 캡슐은 트리에서 부모가 될 위의 계층의 캡슐을 선택합니다.
더 높은 수준의 시각 시스템을 위해, 이 반복적인 프로세스는 부품을 전체적으로 할당하는 문제를 해결할 것입니다.

활성 캡슐 내의 뉴런의 활동은 이미지에 존재하는 특정 개체의 다양한 속성을 나타냅니다.
이러한 속성에는 포즈 (위치, 크기, 방향), 변형, 속도, 알베도(반사하는 태양 광선의 비율), 색조, 텍스처 등과 같은 다양한 유형의 인스턴스화 매개 변수가 포함될 수 있습니다.
매우 특별한 속성 중 하나는 이미지에 인스턴스화 된 엔터티가 있다는 것입니다.
존재를 표현하는 분명한 방법은 엔티티가 존재할 확률을 출력하는 별도의 물류 단위를 사용하는 것입니다.
이 논문에서 우리는 엔티티의 존재를 나타내기 위해 인스턴스화 매개 변수의 벡터의 전체 길이를 사용하고 벡터의 방향을 엔티티의 속성을 나타내도록 하는 흥미로운 대안을 탐구한다.
우리는 캡슐의 벡터 출력의 길이가 벡터의 방향을 변경하지 않고 크기를 줄이는 비선형 성을 적용하여 1을 초과할 수 없도록 보장합니다.

캡슐의 출력이 벡터인 사실은 강력한 동적 라우팅 메커니즘을 사용하여 캡슐의 출력이 위의 계층의 적절한 부모에게 전송되도록 보장합니다.
초기에 출력은 가능한 모든 부모에게 전달되지만 합계 계수 1로 축소됩니다.
가능한 각 부모에 대해 캡슐은 자체 출력에 가중치 행렬을 곱하여 "예측 벡터"를 계산합니다.
이 예측 벡터가 가능한 부모의 출력과 큰 스칼라 곱을 갖는다면, 그 부모에 대한 결합 계수를 증가시키고 다른 부모에 대해서는 감소시키는 하향식 피드백이 있다.
이것은 캡슐이 그 부모에게주는 기여를 증가시키므로, 캡슐의 예측에서 스칼라 내적을 부모의 출력과 함께 더 증가시킨다.
이러한 유형의 "라우팅 별 계약"은 최대 풀링에 의해 구현된 매우 원시적인 형태의 라우팅보다 훨씬 효과적입니다.
최대 풀링 방법은 한 계층의 뉴런이 아래 계층의 로컬 풀에 있는 가장 활동적인 기능 감지기를 제외한 모든 것을 무시하도록 허용합니다.
우리는 우리의 동적 라우팅 메커니즘이 매우 겹치는 객체를 세분화하기 위해 필요한 "설명하기"를 구현하는 효과적인 방법임을 입증합니다.

컨볼루션 신경망 (CNN)은 학습된 특징 검출기의 번역된 모형을 사용합니다.
이를 통해 이미지의 한 위치에서 얻은 좋은 가중치에 대한 지식을 이미지의 다른 위치로 변환 할 수 있습니다.
이것은 이미지 해석에 매우 유용한 것으로 입증되었습니다.
우리가 CNN의 스칼라 출력 특징 검출기를 vector-output 캡슐로 대체하고 최대 풀링을 "라우팅별 계약"(routing-by-agreement)으로 대체하더라도 우리는 여전히 학습된 지식을 공간 전체에 걸쳐 복제하고자 합니다.
이를 위해 캡슐의 마지막 레이어를 제외한 모든 레이어를 컨볼루션(convolutional)으로 만듭니다.
CNN과 마찬가지로, 우리는 더 높은 수준의 캡슐이 이미지의 더 큰 영역을 커버하도록 만듭니다.
그러나 최대 풀링과 달리 우리는 영역 내의 엔티티의 정확한 위치에 대한 정보를 버리지 않습니다.
저급 캡슐의 경우, 위치 정보는 어떤 캡슐이 활성 상태인지 "장소 코드화(place-coded)"가 되어 있습니다.
계층 구조가 올라감에 따라 점점 더 많은 위치 정보가 캡슐의 출력 벡터의 실수 값 구성 요소에서 "비율로 코딩(rate-coded)" 됩니다.
높은 수준의 캡슐이 더 많은 자유도를 가진 더 복잡한 엔티티를 나타내는 사실과 결합된 장소 코딩에서 레이트 코딩으로의 전환은 우리가 계층을 오름에 따라 캡슐의 차원이 증가해야 함을 암시합니다

## 02 How the vector inputs and outputs of a capsule are computed



























---
