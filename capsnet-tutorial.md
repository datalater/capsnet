(c) JMC 2018

---

## Summary

**01 캡슐넷은 무엇일까요**: 캡슐넷은 이미지로부터 인스턴스화 매개변수를 찾는 네트워크입니다.

**PLUS+ 캡슐이란 무엇일까요**: 캡슐이란 특정 위치에서 특정 물체의 존재 여부와 인스턴스화 매개변수를 예측하는 함수를 말합니다.



---

## 01 캡슐넷은 무엇일까요?

캡슐넷은 인버스 그래픽을 수행하는 신경망입니다.

**컴퓨터 그래픽**: instantiation parameters → rendering → image

컴퓨터 그래픽은 어떤 그림을 추상적으로 접근합니다.
예를 들면 사각형이 있는데 x=20이고 y=30, 회전 각도 16도 등으로 말이죠.
이처럼 각 물체의 종류는 다양한 instantiation parameter를 가집니다.
이렇게 instantiation parameter(인스턴스화 매개변수)를 설정한 다음에 rendering function을 호출해서 파라미터에 상응하는 이미지를 얻습니다.
이게 컴퓨터 그래픽 방식입니다.

**인버스 그래픽**: image →inverse rendering → instantiation parameters

인버스 그래픽은 컴퓨터 그래픽 과정을 거꾸로 뒤집은 것입니다.
이미지에서 시작해서 그 이미지가 어떤 물체를 포함하고 있고 인스턴스화 매개변수가 어떻게 되는지 찾습니다.
캡슐넷은 바로 인버스 그래픽을 수행하는 신경망입니다.

## 02 캡슐넷은 어떻게 작동할까요?

**캡슐넷**: image → inverse rendering → capsule activation

캡슐넷은 여러 캡슐로 구성되어 있습니다.
캡슐이란 특정 위치에서 특정 물체의 존재 여부와 인스턴스화 매개변수를 예측하는 함수를 말합니다.
예를 들면, 50개의 캡슐을 포함하는 신경망이 있습니다.
화살표는 각 캡슐의 아웃풋 벡터를 나타냅니다.
검은색 화살표는 사각형을 찾는 캡슐의 아웃풋 벡터이고 파란색 화살표는 삼각형을 찾는 캡슐의 아웃풋 벡터입니다.
아웃풋 벡터의 길이는 캡슐이 찾는 물체가 실제로 존재할 확률을 나타냅니다.
대부분의 화살표는 길이가 매우 작은데 이는 그 캡슐들이 그 어느 것도 감지를 못했다는 뜻인 반면, 두 개의 화살표가 매우 길이가 긴데 그것은 해당 위치의 캡슐들이 찾고 있는 물체가 확실하게 존재한다는 것을 뜻합니다.

캡슐의 아웃풋(액티베이션) 벡터인 화살표의 방향은 물체의 인스턴스화 매개변수를 인코드하고 있습니다.
예를 들어 물체의 회전 각도나 굵기, 얼마나 뻗쳐있는지, 기울어 있는지 등에 대한 매개변수이죠.
여기서는 간단하게 말하기 위해 각도라고 하겠지만, 실제 캡슐 네트워크에서는 액티베이션 벡터는 5차원 또는 10차원이나 그 이상의 차원을 가질 것입니다.

**액티베이션 벡터 추출**: image → convolutional layers → capsule activation

실제로 이렇게 이미지에서 캡슐 액티베이션 벡터를 추출하는 좋은 방법은 몇 개의 컨볼루션 레이어를 적용하는 것입니다.
여러 개의 컨볼루션 레이어를 거치면 여러 개의 피처맵이 나옵니다.

**Reshape**:

피처맵을 reshape 하면 각 위치에 대한 여러 개의 벡터를 구할 수 있습니다.
예를 들어, 컨볼루션 레이어의 아웃풋이 2개의 물체(직사각형, 삼각형)에 9개의 필터를 적용해서 18개라고 해봅시다.
그러면 각 위치마다 9차원을 가진 2개의 벡터로 reshape 할 수 있습니다.
또한 6차원을 가진 3개의 벡터로 reshape 할 수도 있습니다.

**Squash**:

각 위치에 두 개의 벡터가있는 캡슐 네트워크처럼 보일 것입니다.
마지막 단계는 모든 벡터의 길이가 최대 1을 넘지 않도록 만드는 것입니다.
왜냐하면 벡터의 길이가 확률을 나타내야 하기 때문입니다.
이 작업을 하기 위해 squash function을 적용합니다.
squash function은 벡터의 방향은 보존하되 길이만 0부터 1사이로 조절합니다.

## 03 캡슐넷의 핵심인 Equivariance는 무엇일까요?

**Equivariance**:

캡슐 네트워크의 핵심 특징은 네트워크가 물체의 포즈나 위치에 대한 자세한 정보를 신경망 내내 끝까지 보존한다는 것입니다.
예를 들어, 이미지를 살짝 회전시키면 액티베이션 벡터 또한 살짝 바뀌게 됩니다.
이를 equivariance(등가)라고 합니다.
일반적인 컨볼루션 네트워크에서는 여러 개의 풀링 레이어가 있습니다.
그리고 안타깝게도 풀링 레이어는 정보를 잃어버리는 경향이 있습니다.
예를 들면 물체의 정확한 위치라든지 포즈와 같은 정보를 잃어버립니다.
정보의 손실은 물체를 분류할 때는 큰 문제가 되지 않지만 정확한 위치와 포즈를 요구하는 이미지 세분화 또는 물체 인식에서는 큰 어려움으로 작용합니다.
캡슐이 equivariant (동등)하다는 것은 이미지 세분화와 물체 인식에서 매우 유망하게 만듭니다.

## 04 캡슐넷의 구체적인 분석

이제 캡슐 네트워크가 여러 계층의 부분으로 구성되는 물체를 어떻게 다루는지 살펴봅시다.
예를 들어, 보트가 있는데 보트의 인스턴스화 매개변수로는 x=22, y=28, 회전각도=16도로 설정되어 있습니다.
보트는 여러 개의 부분으로 구성됩니다.
여기서는 하나의 직사각형과 하나의 삼각형으로 구성됩니다.
boat={rectangle, triangle}.
인스턴스화 매개변수를 바탕으로 rendering을 시키면 삼각형 돛과 사각형 선체로 이루어진 이미지가 나타납니다.

이제 이 과정을 반대로 합니다.
이미지에서 시작하여 물체를 구성하는 더 작은 단위의 물체(hierarchy of parts)에 대한 인스턴스화 매개변수로 갑니다.
여기서 이미지가 특정 위치와 방향을 가진 삼각형과 사각형으로 이루어졌다는 것뿐만 아니라 그 물체들이 집이 아니라 보트를 구성한다는 것도 알아냅니다.
캡슐넷이 이 과정을 어떻게 처리하는지 알아봅시다.

**01 프라이머리 캡슐의 아웃풋 얻기:**: 컨볼루션-reshape-squash

첫 단계는 몇 개의 컨볼루션 레이어를 거쳐서, 레이어의 아웃풋을 벡터 형태로 reshape합니다.
그리고 각 벡터의 길이를 squash 합니다.
이 과정을 거치면 primary capsules의 아웃풋을 얻을 수 있습니다.
이것이 캡슐 네트워크의 첫 번째 레이어입니다.

**02 다음 레이어의 아웃풋을 예측하기**: dot product

다음 단계는 대부분의 마법과 캡슐 네트워크의 복잡성이 발생하는 단계입니다.
첫 번째 레이어에 있는 모든 캡슐은 다음 레이어의 모든 캡슐 아웃풋을 예측합니다.
이게 무슨 말일까요?
첫 번째 레이어의 캡슐은 두 번째 레이어 캡슐이 출력 할 내용을 예측합니다.

예를 들어, 사각형을 감지한 캡슐을 생각해봅시다.
이를 사각형 캡슐이라고 부르겠습니다.
다음 레이어에 오직 2개의 캡슐만 있다고 가정합시다.
하우스 캡슐과 보트 캡슐입니다.
사각형 캡슐이 16도 회전한 사각형을 감지(인식)했기 때문에 사각형 캡슐은 하우스 캡슐이 16도 회전한 하우스를 감지할 것이라고 예측합니다.
또한 보트 캡슐도 16도 회전한 보트를 감지할 것이라고 예측합니다.
그래야 사각형의 방향이 일관성 있게 유지됩니다.
이러한 예측을 하려면 사각형 캡슐이 하는 일은 변형 행렬 $W_{ij}$와 사각형 캡슐의 액티베이션 벡터인 $u_{i}$를 dot product 하는 것입니다.
훈련을 하는 동안 네트워크는 점차적으로 첫 번째 및 두 번째 계층의 각 캡슐 쌍에 대한 변형 행렬을 학습합니다.
즉, 캡슐 네트워크는 모든 부분(사각형)-전체(보트)에 관한 관계를 학습합니다.
예를 들어, 하우스의 벽과 지붕 사이의 각도 같은 것을 말이죠.

이제 삼각형 캡슐이 예측하는 것을 살펴봅시다.
이번에는 좀 더 흥미롭습니다.
삼각형의 회전각도가 주어진 상태에서, 삼각형 캡슐은 하우스 캡슐이 뒤엎어진 하우스 인식할 것이라고 예측합니다.
보트 캡슐은 16도 회전한 보트를 인식할 것이라고 예측하죠.
그래야 삼각형의 각도가 일관성을 갖게 되기 때문입니다.

**다음 레이어의 아웃풋 계산하기**: 라우트

이제 우리는 여러 개의 예측된 아웃풋이 있습니다.
이걸로 뭘 할까요?
보다시피, 사각형 캡슐과 삼각형 캡슐은 보트 캡슐이 출력할 내용과 상당히 일치합니다.
다른 말로 하면, 그들은 이 방법으로 배치된 보트가 자신의 위치와 회전을 설명한다는 데 동의합니다.
그리고 하우스 캡슐이 출력할 내용에는 서로 완전히 다른 예측을 합니다.
그러므로 사각형과 삼각형은 하우스의 일부가 아니라 보트의 일부라는 것이 더 말이 됩니다.

이제 삼각형과 사각형이 보트의 일부라는 것을 알았으니, 삼각형 캡슐과 사각형 캡슐의 아웃풋은 보트 캡슐로 보내면 됩니다.
삼각형 캡슐과 사각형 캡슐의 아웃풋을 보트 캡슐이 아닌 다른 캡슐에 보내면 오히려 노이즈가 되므로 다른 캡슐로 보낼 필요가 전혀 없습니다.
삼각형 캡슐과 사각형 캡슐의 아웃풋은 보트 캡슐로만 보내져야 합니다.
이를 두고 삼각형 캡슐과 사각형 캡슐이 보트 캡슐로 "라우트" 되어야 한다고 말하며, 이러한 과정을 "routing by agreement"라고 부릅니다.

**라우팅 바이 어그리먼트**:

라우팅 바이 어그리먼트를 하면 몇 가지 장점이 있습니다.
첫째, 캡슐의 아웃풋이 오직 적절한 그 다음 레이어의 캡슐에만 전달되기 때문에, 그 다음 레이어의 캡슐들은 더 깨끗한 입력 신호를 받게 되고 물체의 위치를 더 정확하게 결정할 수 있게 됩니다.
둘째, 액티베이션 벡터의 길(path)을 봄으로써 쉽게 물체의 일부분(hierarchy of parts)을 쉽게 네비게이트할 수 있으며 어떤 부분이 어떤 물체에 속하는지 알 수 있습니다.
(가령, 사각형이 보트에 속한다거나 삼각형이 보트에 속한다거나 등등)
마지막으로 라우팅 바이 어그리먼트를 하면 겹치는 객체로 복잡한 장면을 파싱하는 데 도움이 됩니다.

## 05 라우팅 바이 어그리먼트 작동 방식

**clusters of agreement**:

여기에 low-level 캡슐이 예측한 보트가 취할 수 있는 다양한 자세들이 있습니다.
그래프 위의 점 중에 하나는 사각형 캡슐이 생각하기에 가장 그럴듯한 보트의 자세를 나타냅니다.
다른 점 하나는 삼각형 캡슐이 예측하는 가장 그럴듯한 보트의 자세를 나타냅니다.
만약 low-level 캡슐이 여러 개라면 그만큼 보트 캡슐에 대해 예측하는 벡터도 여러 개일 것입니다.

이 예시에서 포즈 파라미터는 2종류입니다.
하나는 회전각도이고 나머지는 보트의 크기를 나타냅니다.
앞에서도 말했지만, 포즈 파라미터들은 다양한 시각적 특징들을 잡아낼 수 있습니다.
가령, 기울기, 굵기, 정확한 위치 등이 있습니다.

처음 우리가 해야 할 일은 모든 예측 벡터의 평균을 계산하는 것입니다.
그러면 평균 벡터가 나옵니다.
다음 단계는 평균 벡터와 각 예측 벡터 간의 거리를 구합니다.
여기서는 유클리디안 거리를 사용할 거지만 실제 캡슐넷에서는 scalar product를 합니다.
기본적으로 우리가 하고자 하는 것은 각각의 예측 벡터가 평균 예측 벡터와 얼마나 일치하는지를 보는 것입니다.
이러한 agreement measure를 사용해서 해당하는 예측 벡터의 가중치를 업데이트시킬 수 있습니다.

평균 벡터와 거리가 먼 예측 벡터는 가중치 값이 매우 작아지고, 평균 벡터와 가장 가까이 있는 예측 벡터의 가중치 값은 매우 커집니다.
클러스터로 구분하면 평균 벡터와 가까이 있는 것은 검정색 멀리 있는 것은 옅은 파란색으로 칠할 수 있습니다.
여기서 평균 벡터를 다시 구합니다.
이는 가중 평균이라고 할 수 있습니다.
가중 평균을 구하면 평균 벡터의 위치가 검정색과 짙은 파란색 클러스터의 중심과 가깝게 이동합니다.
여기서 가중치를 다시 업데이트합니다.
그러면 클러스터 안에 있는 예측 벡터들은 대부분 검정색으로 변합니다.
여기서 평균 벡터를 또 업데이트합니다.
이런 과정을 여러 번 반복합니다.
실제로 3번에서 5번 사이로 반복하면 충분합니다.
k-means 클러스터링 알고리즘과 유사하다는 것을 알 수 있습니다.

이런 방법으로 cluster of agreement를 구합니다.
이제 전체 알고리즘이 어떻게 작동하는지 세세하게 살펴봅시다.

**routing weights**:

















---
